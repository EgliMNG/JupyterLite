{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b9880fe",
   "metadata": {},
   "source": [
    "# Machine Learning Regression und Klassifikation Vertiefung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64193641",
   "metadata": {},
   "source": [
    "## TEIL A: Regression mit Hauspreisberechnung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65505f5c",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; border: 5px solid #a10000ff;\">\n",
    "\n",
    "**Hinweis:** In den Codezellen sind jeweils einige Codeteile nicht programmiert. Diesen Code müssen Sie ergänzen. Die jeweiligen Stellen sind mit einem Kommentar und dem Keyword **TODO** vermerkt und z.T. Stellen mit ... markiert.\n",
    "\n",
    "Ausserdem gibt es einige assert Statements. Diese geben einen Fehler aus, sollte etwas bei Ihrer Programmierung nicht korrekt sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9336170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e0ed32",
   "metadata": {},
   "source": [
    "In diesem Dataset wurden verschiedene Eigenschaften von Liegenschaften erfasst. \n",
    "\n",
    "Dabei soll nun von den Eigenschaften auf den Hauspreis geschlossen werden. Der Hauspreis ist somit die **Zielvariable** oder engl. *Target*, ähnlich dem Label in der Klassifikation.\n",
    "\n",
    "Die Berechnungen des Hauspreises, werden wir mit einem Regressionsmodell machen.\n",
    "\n",
    "Das Dataset das wir benutzten, ist das California Housing Dataset. **Dieses ist bereits vorbereitet**:\n",
    "https://www.kaggle.com/datasets/camnugent/california-housing-prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b0b1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir laden den Datensatz in ein Pandas DataFrame und zeigen die ersten Zeilen an\n",
    "df_housing = pd.read_csv(\"./data/housing.csv\")\n",
    "df_housing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e65082",
   "metadata": {},
   "source": [
    "### Aufgabe 1\n",
    "\n",
    "Sie haben sich sicherlich die Features im Dataframe angeschaut. Machine Learning Modelle benötigen die Daten als Zahlen um diese im Features Space abbilden zu können. Jedoch haben wir mit ocean_proximity ein Feature das Kategorische Daten enthält.\n",
    "\n",
    "**Frage:** Um welche Art von Skalentyp handelt es sich? Wie übertragen wir ein solches Feature in einen Feature Space?\n",
    "\n",
    "<br>\n",
    "<details>\n",
    "<summary><b>Lösung: Klicke hier für die Lösung.</b></summary>\n",
    "\n",
    "Es handelt sich um eine Nominalskala. Die Ordnung ist nicht klar gegeben. Es ist z.B. nicht klar ob Island näher am Ozean ist wie Near Ocean zum Beispiel.\n",
    "\n",
    "Diese können wir mit dem sogenannten One-Hot-Encoding in einen mathematischen Raum übertragen. Dies geschieht indem wir für jede Kategorie eine neue Dimension anlegen und dort eine 1 vermerken wenn die Kategorie zutrifft und bei allen anderen eine 0. Wir nutzen dazu den One-Hot-Encoder von Scikit-learn.\n",
    "\n",
    "Zusätzlich entfernen wir noch alle Data Samples die leere Werte haben.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557f4b8b",
   "metadata": {},
   "source": [
    "Wir listen nun einmal alle Arten von Werten die ocean_proximity haben kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030101bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir verwenden OneHotEncoder aus sklearn.preprocessing\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# TODO Konfiguriere das One-Hot-Encoding auf der Spalte 'ocean_proximity' indem du das DataFrame df_housing mit der Spaltenangabe als Parameter einfügst. Beispiel: ohe.fit(df_iris[['petal length (cm)']])\n",
    "ohe.fit(...)\n",
    "\n",
    "# Wir erstellen ein neues DataFrame mit den kodierten Spalten und fügen sie dem ursprünglichen DataFrame hinzu. Danach entfernen wir die ursprüngliche Spalte 'ocean_proximity'.\n",
    "df_housing_encoded = pd.concat([df_housing, pd.DataFrame(ohe.transform(df_housing[['ocean_proximity']]), columns=ohe.get_feature_names_out(['ocean_proximity']))], axis=1)\n",
    "df_housing_encoded.drop('ocean_proximity', axis=1, inplace=True)\n",
    "\n",
    "# Wir entfernen Zeilen mit fehlenden Werten, da diese nicht für das Training des Modells verwendet werden können\n",
    "df_housing_encoded.dropna(inplace=True)\n",
    "\n",
    "df_housing_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fc8267",
   "metadata": {},
   "source": [
    "### Aufgabe 1.1 : Verleiche nun die Ausgabe hier mit dem initialen DataFrame weiter oben. Wie viele Spalten sind nun dazugekommen und welche wurde entfernt?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5375f6",
   "metadata": {},
   "source": [
    "### Skalierung\n",
    "\n",
    "Wir möchten nun noch die Daten normalisieren. Dies hilft einigen Modellen zum Beispiel künstlichen Neuronalen Netzwerken schneller zu optimieren und zu lernen.\n",
    "Wir wenden die min-max-Skalierung an. Das heisst alle Features haben danach einen minimalen Wert von 0 und einen maximalen Wert von 1.\n",
    "\n",
    "**Führen Sie die nächste Zelle aus:**\n",
    "\n",
    "$scaled\\_value = \\frac{value-min}{max - min}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3e4241",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Normalize numerical features with min max scaling\n",
    "\n",
    "# Identify numerical features\n",
    "numerical_features = df_housing_encoded.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Apply min-max scaling\n",
    "for feature in numerical_features:\n",
    "    min_value = df_housing_encoded[feature].min()\n",
    "    max_value = df_housing_encoded[feature].max()\n",
    "    df_housing_encoded[feature] = (df_housing_encoded[feature] - min_value) / (max_value - min_value)\n",
    "\n",
    "df_housing_encoded\n",
    "\n",
    "# prüfen ob die numerischen Features korrekt normalisiert wurden\n",
    "assert (df_housing_encoded[numerical_features].min().min() >= 0) and (df_housing_encoded[numerical_features].max().max() <= 1), \"Die numerischen Features wurden nicht korrekt normalisiert.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a48e1e",
   "metadata": {},
   "source": [
    "### Aufgabe 2\n",
    "\n",
    "Wir unterteilen das Dataset in ein Trainings und Testteil.\n",
    "Dabei nehmen wir 80% Trainingsdaten und 20% Testdaten.\n",
    "\n",
    "Lassen Sie die nächste Zelle laufen und geben Sie darunter aus, wie viele Trainings- und Testdaten Sie haben. **Tipp:** Nutzen Sie .shape oder .len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc6c3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zusatzinfos: Wir Unterteile das Dataset in Trainigns- und Testdaten. Die Spalte 'median_house_value' ist die Zielvariable, die wir vorhersagen möchten. \n",
    "# Deshalb wird sie von den Features getrennt. Wir entfernen die Zielvariable aus den Features bei der Parameterübergabe mit df_housing_encoded.drop('median_house_value', axis=1) und benutze sie als zweiten Parameter in der train_test_split Funktion.\n",
    "\n",
    "X_housing_train, X_housing_test, y_housing_train, y_housing_test = train_test_split(df_housing_encoded.drop('median_house_value', axis=1), df_housing_encoded['median_house_value'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f4ae65",
   "metadata": {},
   "source": [
    "Die **Features** sind nun in dem Variablen mit X beginnend gespeichert. Die **Targets** in den Variablen mit y beginnend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93884f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Zeigen Sie an wie viele Trainings- und Testdaten Sie haben\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe772d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests zur Überprüfung der Aufteilung der Daten in Trainings- und Testdaten\n",
    "assert X_housing_train.shape[0] == 16346, f\"Erwartete Anzahl Trainingsdaten: 16346, aktuell sind es: {X_housing_train.shape[0]}\"\n",
    "assert X_housing_test.shape[0] == 4087 , f\"Erwartete Anzahl Testdaten: 4087, aktuell sind es: {X_housing_test.shape[0]}\"\n",
    "\n",
    "# Prüfe ob median_house_value aus den Features entfernt wurde\n",
    "assert 'median_house_value' not in X_housing_train.columns, \"median_house_value wurde nicht aus den Features entfernt.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0690ff11",
   "metadata": {},
   "source": [
    "### Aufgabe 3\n",
    "\n",
    "1. Nutzen Sie die MLPRegressor Klasse um ein Modell zu instantieren. Die Klasse wurde bereits am Anfang importiert. Sie können die gleichen Parameter verwenden wie in Aufgabe 7 beim MLPClassifier.\n",
    "2. Trainieren Sie nun das Modell mit dem Aufruf der fit(Trainingsdaten, Targets) Methode.\n",
    "\n",
    "Optional: Weitere Infos zur MLPRegressor Klasse: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45141773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir erstellen nun ein Regressionsmodell bestehend aus mehreren Perzeptronen (MLPRegressor)\n",
    "mlp_regressor = MLPRegressor(hidden_layer_sizes=(10,), max_iter=500, random_state=42)\n",
    "\n",
    "# TODO Trainieren Sie das Modell mit den Trainignsdaten als erstes Argument und den zugehörigen Labels als zweites Argument. Tipp: benutzen Sie die X_housing_train und y_housing_train Variablen.\n",
    "mlp_regressor.fit(..., ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05781762",
   "metadata": {},
   "source": [
    "### Aufgabe 4\n",
    "\n",
    "Evaluieren Sie nun ihr Modell mit den Testdaten. Dieses Mal können wir aber nicht die Accuracy nutzen, da diese nur für Klassifikationen geeignet ist.\n",
    "Wir nutzen stattdessen den Root-Mean-Squared-Error. Dieser wird wie folgt berechnet:\n",
    "\n",
    "- $y$: Echtes Label\n",
    "- $\\hat{y}$: Voraussage des Modells\n",
    "\n",
    "$\\text{RMSE} = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2}$\n",
    "\n",
    "In Prosa geschieht hier folgendes:\n",
    "Für jedes Data Samples im Testdatenset wird das echte Label minus der Voraussage gerechnet. Dieses Ergebnis wird quadriert. Danach wird die Summe über alle diese quadrierten \"Fehler\" berechnet und geteilt durch die Anzahl Samples gerechnet. Somit der Mittelwert des quadrierten Fehlers. Zuletzt ziehen wir noch die Wurzel damit das Ergebnis besser interpretierbar wird, bezüglich der Grössenordnung.\n",
    "\n",
    "Vervollständigen Sie den Code um den MSE zu berechnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55863e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir berechnen nun mit dem Modell die Vorhersagen für die Testdaten als einzigen Parameter in der predict-Methode\n",
    "y_housing_pred = mlp_regressor.predict(X_housing_test)\n",
    "\n",
    "#TODO  Wir berechnen den Root Mean Squared Error (RMSE) auf dem Testset\n",
    "mse_test = np.sqrt(np.sum((... - ...)**2) / len(...))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1488a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel Vorhersage des Preises für ein einzelnes Haus aus dem Testset\n",
    "\n",
    "y_housing_pred_single = mlp_regressor.predict(X_housing_test[:1])\n",
    "print(f'Der berechnete Hauswert beträgt: {y_housing_pred_single[0]:.2f}')\n",
    "\n",
    "y_pred_scaled = y_housing_pred_single * (df_housing['median_house_value'].max() - df_housing['median_house_value'].min()) + df_housing['median_house_value'].min()\n",
    "print(f'Der berechnete Hauswert im Originalmaßstab beträgt: {y_pred_scaled[0]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54679056",
   "metadata": {},
   "source": [
    "### Aufgabe 5\n",
    "\n",
    "Wir zeigen nun in einem Scatter Plot noch einige zufällige Datenpunkte an, wobei wir vergleichen möchten was der echte Hauspreis ist und was unser Modell berechnet hat.\n",
    "Lassen Sie die nächste Code Zelle laufen und beantworten Sie die folgende Frage.\n",
    "\n",
    "**Frage**\n",
    "Woran erkennt man einen kleinen Fehler des Modells und wie einen grossen?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4bc3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotte die Vorhersagen des Modells gegen die tatsächlichen Werte nutze aber nur 50 zufällige Datenpunkte und zeichne den Fehler als Linie ein\n",
    "\n",
    "random_indices = np.random.choice(len(y_housing_test), size=50, replace=False)\n",
    "y_housing_pred_sampled = y_housing_pred[random_indices]\n",
    "y_housing_test_sampled = y_housing_test.iloc[random_indices]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.scatter(range(len(y_housing_pred_sampled)), y_housing_pred_sampled, color='red', label='Berechnete Werte')\n",
    "plt.scatter(range(len(y_housing_test_sampled)), y_housing_test_sampled, color='blue', label='Tatsächliche Werte')\n",
    "for i in range(len(y_housing_pred_sampled)):\n",
    "    plt.plot([i, i], [y_housing_pred_sampled[i], y_housing_test_sampled.iloc[i]], color='gray', linestyle='--', linewidth=0.5)\n",
    "plt.xlabel('Testdaten Index')\n",
    "plt.ylabel('Median Hauswert (normalisiert)')\n",
    "plt.title('Vorhersagen vs Tatsächliche Werte des Hauswerts')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a10b4c",
   "metadata": {},
   "source": [
    "## Kontrollfragen: Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9718682d",
   "metadata": {},
   "source": [
    "**Kontrollfrage 3**\n",
    "\n",
    "Was ist der Output einer Regression und wie verhält sich dieser im Vergleich zu der Klassifikation?\n",
    "\n",
    "\n",
    "**Kontrollfrage 4**\n",
    "\n",
    "Wie können jategorische Daten auch für ein Regressionsmodell nutzbar gemacht werden?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
